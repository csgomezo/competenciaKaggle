{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5d3cb4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from livelossplot import PlotLossesKeras\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ddb4c7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo = \"dataTraining.csv\"\n",
    "archivo_test = \"dataTesting.csv\"\n",
    "train_data = pd.read_csv(archivo)\n",
    "test_data = pd.read_csv(archivo_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c63fde78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                      ['Short', 'Drama']\n",
       "1                           ['Comedy', 'Crime', 'Horror']\n",
       "2                      ['Drama', 'Film-Noir', 'Thriller']\n",
       "3                                               ['Drama']\n",
       "4                         ['Action', 'Crime', 'Thriller']\n",
       "                              ...                        \n",
       "7890                                ['Comedy', 'Romance']\n",
       "7891                   ['Action', 'Adventure', 'Fantasy']\n",
       "7892    ['Adventure', 'Musical', 'Fantasy', 'Comedy', ...\n",
       "7893    ['Animation', 'Adventure', 'Drama', 'Family', ...\n",
       "7894      ['Animation', 'Adventure', 'Family', 'Fantasy']\n",
       "Name: genres, Length: 7895, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"genres\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe1e9a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_genres = set(train_data[\"genres\"].apply(lambda cell:\n",
    "                                      ''.join(c for c in cell if c not in \"'[]\").split(', ')).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dc4f8a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0  year                              title  \\\n",
      "0           3107  2003                               Most   \n",
      "1            900  2008          How to Be a Serial Killer   \n",
      "2           6724  1941                     A Woman's Face   \n",
      "3           4704  1954                    Executive Suite   \n",
      "4           2582  1990                      Narrow Margin   \n",
      "...          ...   ...                                ...   \n",
      "7890        8417  2010                 Our Family Wedding   \n",
      "7891        1592  1984                Conan the Destroyer   \n",
      "7892        1723  1955                             Kismet   \n",
      "7893        7605  1982                 The Secret of NIMH   \n",
      "7894         215  2009  Tinker Bell and the Lost Treasure   \n",
      "\n",
      "                                                   plot  \\\n",
      "0     most is the story of a single father who takes...   \n",
      "1     a serial killer decides to teach the secrets o...   \n",
      "2     in sweden ,  a female blackmailer with a disfi...   \n",
      "3     in a friday afternoon in new york ,  the presi...   \n",
      "4     in los angeles ,  the editor of a publishing h...   \n",
      "...                                                 ...   \n",
      "7890  \" our marriage ,  their wedding .  \"  it ' s l...   \n",
      "7891  the wandering barbarian ,  conan ,  alongside ...   \n",
      "7892  like a tale spun by scheherazade ,  kismet fol...   \n",
      "7893  mrs .  brisby ,  a widowed mouse ,  lives in a...   \n",
      "7894  tinker bell journey far north of never land to...   \n",
      "\n",
      "                                                 genres  rating  Film-Noir  \\\n",
      "0                                    ['Short', 'Drama']     8.0          0   \n",
      "1                         ['Comedy', 'Crime', 'Horror']     5.6          0   \n",
      "2                    ['Drama', 'Film-Noir', 'Thriller']     7.2          0   \n",
      "3                                             ['Drama']     7.4          0   \n",
      "4                       ['Action', 'Crime', 'Thriller']     6.6          0   \n",
      "...                                                 ...     ...        ...   \n",
      "7890                              ['Comedy', 'Romance']     4.9          0   \n",
      "7891                 ['Action', 'Adventure', 'Fantasy']     5.8          0   \n",
      "7892  ['Adventure', 'Musical', 'Fantasy', 'Comedy', ...     6.4          0   \n",
      "7893  ['Animation', 'Adventure', 'Drama', 'Family', ...     7.6          0   \n",
      "7894    ['Animation', 'Adventure', 'Family', 'Fantasy']     6.8          0   \n",
      "\n",
      "      Documentary  Fantasy  Biography  ...  Crime  Horror  War  Drama  Action  \\\n",
      "0               0        0          0  ...      0       0    0      0       0   \n",
      "1               0        0          0  ...      0       0    0      0       0   \n",
      "2               0        0          0  ...      0       0    0      0       0   \n",
      "3               0        0          0  ...      0       0    0      0       0   \n",
      "4               0        0          0  ...      0       0    0      0       0   \n",
      "...           ...      ...        ...  ...    ...     ...  ...    ...     ...   \n",
      "7890            0        0          0  ...      0       0    0      0       0   \n",
      "7891            0        0          0  ...      0       0    0      0       0   \n",
      "7892            0        0          0  ...      0       0    0      0       0   \n",
      "7893            0        0          0  ...      0       0    0      0       0   \n",
      "7894            0        0          0  ...      0       0    0      0       0   \n",
      "\n",
      "      Adventure  Comedy  Music  Animation  Mystery  \n",
      "0             0       0      0          0        0  \n",
      "1             0       0      0          0        0  \n",
      "2             0       0      0          0        0  \n",
      "3             0       0      0          0        0  \n",
      "4             0       0      0          0        0  \n",
      "...         ...     ...    ...        ...      ...  \n",
      "7890          0       0      0          0        0  \n",
      "7891          0       0      0          0        0  \n",
      "7892          0       0      0          0        0  \n",
      "7893          0       0      0          0        0  \n",
      "7894          0       0      0          0        0  \n",
      "\n",
      "[7895 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "#train_data[\"genres\"].explode()\n",
    "for a in list_genres:\n",
    "    train_data[a]=0\n",
    "    \n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aa634d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlo\\AppData\\Local\\Temp\\ipykernel_13536\\1858948565.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_data[a].loc[train_data[\"genres\"].str.contains(a)]=1\n"
     ]
    }
   ],
   "source": [
    "for a in list_genres:\n",
    "    train_data[a].loc[train_data[\"genres\"].str.contains(a)]=1\n",
    "\n",
    "#train_data.apply(lambda x: str(\"Mystery\") in train_data[\"genres\"], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c308e718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>plot</th>\n",
       "      <th>genres</th>\n",
       "      <th>rating</th>\n",
       "      <th>Film-Noir</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Biography</th>\n",
       "      <th>...</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Horror</th>\n",
       "      <th>War</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Music</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Mystery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9080</td>\n",
       "      <td>1945</td>\n",
       "      <td>Pursuit to Algiers</td>\n",
       "      <td>holmes and watson are recruited in a serpentin...</td>\n",
       "      <td>['Adventure', 'Crime', 'Mystery', 'Romance']</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>8067</td>\n",
       "      <td>1979</td>\n",
       "      <td>Quintet</td>\n",
       "      <td>in the distant future the world is in the grip...</td>\n",
       "      <td>['Drama', 'Mystery', 'Sci-Fi']</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>7692</td>\n",
       "      <td>2004</td>\n",
       "      <td>Wicker Park</td>\n",
       "      <td>in chicago ,  advertising executive and former...</td>\n",
       "      <td>['Drama', 'Mystery', 'Romance', 'Thriller']</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>6930</td>\n",
       "      <td>2014</td>\n",
       "      <td>The Scribbler</td>\n",
       "      <td>the scribbler follows suki  ( katie cassidy ) ...</td>\n",
       "      <td>['Mystery', 'Sci-Fi', 'Thriller']</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>10368</td>\n",
       "      <td>1946</td>\n",
       "      <td>The Blue Dahlia</td>\n",
       "      <td>when lt .  commander johnny morrison returns h...</td>\n",
       "      <td>['Crime', 'Film-Noir', 'Mystery', 'Thriller']</td>\n",
       "      <td>7.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7819</th>\n",
       "      <td>5720</td>\n",
       "      <td>2014</td>\n",
       "      <td>Digging Up the Marrow</td>\n",
       "      <td>a documentary exploring genre based monster ar...</td>\n",
       "      <td>['Biography', 'Drama', 'Fantasy', 'Horror', 'M...</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7856</th>\n",
       "      <td>9272</td>\n",
       "      <td>2012</td>\n",
       "      <td>The Motel Life</td>\n",
       "      <td>two brothers who are forced to leave reno afte...</td>\n",
       "      <td>['Drama', 'Mystery', 'Thriller']</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7869</th>\n",
       "      <td>10426</td>\n",
       "      <td>2006</td>\n",
       "      <td>The Da Vinci Code</td>\n",
       "      <td>the story tells the investigation started by s...</td>\n",
       "      <td>['Mystery', 'Thriller']</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7872</th>\n",
       "      <td>3809</td>\n",
       "      <td>2014</td>\n",
       "      <td>Veronica Mars</td>\n",
       "      <td>former teenage private eye and now an aspiring...</td>\n",
       "      <td>['Crime', 'Drama', 'Mystery', 'Thriller']</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7881</th>\n",
       "      <td>5939</td>\n",
       "      <td>2002</td>\n",
       "      <td>The Bourne Identity</td>\n",
       "      <td>on a stormy night ,  a young man is pulled out...</td>\n",
       "      <td>['Action', 'Mystery', 'Thriller']</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>759 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  year                  title  \\\n",
       "19          9080  1945     Pursuit to Algiers   \n",
       "30          8067  1979                Quintet   \n",
       "39          7692  2004            Wicker Park   \n",
       "41          6930  2014          The Scribbler   \n",
       "65         10368  1946        The Blue Dahlia   \n",
       "...          ...   ...                    ...   \n",
       "7819        5720  2014  Digging Up the Marrow   \n",
       "7856        9272  2012         The Motel Life   \n",
       "7869       10426  2006      The Da Vinci Code   \n",
       "7872        3809  2014          Veronica Mars   \n",
       "7881        5939  2002    The Bourne Identity   \n",
       "\n",
       "                                                   plot  \\\n",
       "19    holmes and watson are recruited in a serpentin...   \n",
       "30    in the distant future the world is in the grip...   \n",
       "39    in chicago ,  advertising executive and former...   \n",
       "41    the scribbler follows suki  ( katie cassidy ) ...   \n",
       "65    when lt .  commander johnny morrison returns h...   \n",
       "...                                                 ...   \n",
       "7819  a documentary exploring genre based monster ar...   \n",
       "7856  two brothers who are forced to leave reno afte...   \n",
       "7869  the story tells the investigation started by s...   \n",
       "7872  former teenage private eye and now an aspiring...   \n",
       "7881  on a stormy night ,  a young man is pulled out...   \n",
       "\n",
       "                                                 genres  rating  Film-Noir  \\\n",
       "19         ['Adventure', 'Crime', 'Mystery', 'Romance']     7.2          0   \n",
       "30                       ['Drama', 'Mystery', 'Sci-Fi']     5.2          0   \n",
       "39          ['Drama', 'Mystery', 'Romance', 'Thriller']     7.0          0   \n",
       "41                    ['Mystery', 'Sci-Fi', 'Thriller']     5.4          0   \n",
       "65        ['Crime', 'Film-Noir', 'Mystery', 'Thriller']     7.2          1   \n",
       "...                                                 ...     ...        ...   \n",
       "7819  ['Biography', 'Drama', 'Fantasy', 'Horror', 'M...     5.8          0   \n",
       "7856                   ['Drama', 'Mystery', 'Thriller']     6.0          0   \n",
       "7869                            ['Mystery', 'Thriller']     6.6          0   \n",
       "7872          ['Crime', 'Drama', 'Mystery', 'Thriller']     6.8          0   \n",
       "7881                  ['Action', 'Mystery', 'Thriller']     7.9          0   \n",
       "\n",
       "      Documentary  Fantasy  Biography  ...  Crime  Horror  War  Drama  Action  \\\n",
       "19              0        0          0  ...      1       0    0      0       0   \n",
       "30              0        0          0  ...      0       0    0      1       0   \n",
       "39              0        0          0  ...      0       0    0      1       0   \n",
       "41              0        0          0  ...      0       0    0      0       0   \n",
       "65              0        0          0  ...      1       0    0      0       0   \n",
       "...           ...      ...        ...  ...    ...     ...  ...    ...     ...   \n",
       "7819            0        1          1  ...      0       1    0      1       0   \n",
       "7856            0        0          0  ...      0       0    0      1       0   \n",
       "7869            0        0          0  ...      0       0    0      0       0   \n",
       "7872            0        0          0  ...      1       0    0      1       0   \n",
       "7881            0        0          0  ...      0       0    0      0       1   \n",
       "\n",
       "      Adventure  Comedy  Music  Animation  Mystery  \n",
       "19            1       0      0          0        1  \n",
       "30            0       0      0          0        1  \n",
       "39            0       0      0          0        1  \n",
       "41            0       0      0          0        1  \n",
       "65            0       0      0          0        1  \n",
       "...         ...     ...    ...        ...      ...  \n",
       "7819          0       0      0          0        1  \n",
       "7856          0       0      0          0        1  \n",
       "7869          0       0      0          0        1  \n",
       "7872          0       0      0          0        1  \n",
       "7881          0       0      0          0        1  \n",
       "\n",
       "[759 rows x 30 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[train_data[\"Mystery\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "69889280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0  year                              title  \\\n",
      "0           3107  2003                               Most   \n",
      "1            900  2008          How to Be a Serial Killer   \n",
      "2           6724  1941                     A Woman's Face   \n",
      "3           4704  1954                    Executive Suite   \n",
      "4           2582  1990                      Narrow Margin   \n",
      "...          ...   ...                                ...   \n",
      "7890        8417  2010                 Our Family Wedding   \n",
      "7891        1592  1984                Conan the Destroyer   \n",
      "7892        1723  1955                             Kismet   \n",
      "7893        7605  1982                 The Secret of NIMH   \n",
      "7894         215  2009  Tinker Bell and the Lost Treasure   \n",
      "\n",
      "                                                   plot  \\\n",
      "0     most is the story of a single father who takes...   \n",
      "1     a serial killer decides to teach the secrets o...   \n",
      "2     in sweden ,  a female blackmailer with a disfi...   \n",
      "3     in a friday afternoon in new york ,  the presi...   \n",
      "4     in los angeles ,  the editor of a publishing h...   \n",
      "...                                                 ...   \n",
      "7890  \" our marriage ,  their wedding .  \"  it ' s l...   \n",
      "7891  the wandering barbarian ,  conan ,  alongside ...   \n",
      "7892  like a tale spun by scheherazade ,  kismet fol...   \n",
      "7893  mrs .  brisby ,  a widowed mouse ,  lives in a...   \n",
      "7894  tinker bell journey far north of never land to...   \n",
      "\n",
      "                                                 genres  rating  Film-Noir  \\\n",
      "0                                    ['Short', 'Drama']     8.0          0   \n",
      "1                         ['Comedy', 'Crime', 'Horror']     5.6          0   \n",
      "2                    ['Drama', 'Film-Noir', 'Thriller']     7.2          1   \n",
      "3                                             ['Drama']     7.4          0   \n",
      "4                       ['Action', 'Crime', 'Thriller']     6.6          0   \n",
      "...                                                 ...     ...        ...   \n",
      "7890                              ['Comedy', 'Romance']     4.9          0   \n",
      "7891                 ['Action', 'Adventure', 'Fantasy']     5.8          0   \n",
      "7892  ['Adventure', 'Musical', 'Fantasy', 'Comedy', ...     6.4          0   \n",
      "7893  ['Animation', 'Adventure', 'Drama', 'Family', ...     7.6          0   \n",
      "7894    ['Animation', 'Adventure', 'Family', 'Fantasy']     6.8          0   \n",
      "\n",
      "      Documentary  Fantasy  Biography  ...  Crime  Horror  War  Drama  Action  \\\n",
      "0               0        0          0  ...      0       0    0      1       0   \n",
      "1               0        0          0  ...      1       1    0      0       0   \n",
      "2               0        0          0  ...      0       0    0      1       0   \n",
      "3               0        0          0  ...      0       0    0      1       0   \n",
      "4               0        0          0  ...      1       0    0      0       1   \n",
      "...           ...      ...        ...  ...    ...     ...  ...    ...     ...   \n",
      "7890            0        0          0  ...      0       0    0      0       0   \n",
      "7891            0        1          0  ...      0       0    0      0       1   \n",
      "7892            0        1          0  ...      0       0    0      0       0   \n",
      "7893            0        1          0  ...      0       0    0      1       0   \n",
      "7894            0        1          0  ...      0       0    0      0       0   \n",
      "\n",
      "      Adventure  Comedy  Music  Animation  Mystery  \n",
      "0             0       0      0          0        0  \n",
      "1             0       1      0          0        0  \n",
      "2             0       0      0          0        0  \n",
      "3             0       0      0          0        0  \n",
      "4             0       0      0          0        0  \n",
      "...         ...     ...    ...        ...      ...  \n",
      "7890          0       1      0          0        0  \n",
      "7891          1       0      0          0        0  \n",
      "7892          1       1      1          0        0  \n",
      "7893          1       0      0          1        0  \n",
      "7894          1       0      0          1        0  \n",
      "\n",
      "[7895 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d6ca0dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7895, 1000)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(max_features=1000)\n",
    "X_dtm = vect.fit_transform(train_data['plot'])\n",
    "X_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e96aee52",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['genres'] = train_data['genres'].map(lambda x: eval(x))\n",
    "le = MultiLabelBinarizer()\n",
    "y_genres = le.fit_transform(train_data['genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0cf5d190",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train_genres, y_test_genres = train_test_split(X_dtm, y_genres, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ddc81dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=RandomForestClassifier(max_depth=10, n_jobs=-1,\n",
       "                                                     random_state=42))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##First classifier\n",
    "clf = OneVsRestClassifier(RandomForestClassifier(n_jobs=-1, n_estimators=100, max_depth=10, random_state=42))\n",
    "clf.fit(X_train, y_train_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a74dd96e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7812262183677007"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicción del modelo de clasificación\n",
    "y_pred_genres = clf.predict_proba(X_test)\n",
    "\n",
    "# Impresión del desempeño del modelo\n",
    "roc_auc_score(y_test_genres, y_pred_genres, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c37f4a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_dtm = vect.transform(test_data['plot'])\n",
    "\n",
    "cols = ['p_Action', 'p_Adventure', 'p_Animation', 'p_Biography', 'p_Comedy', 'p_Crime', 'p_Documentary', 'p_Drama', 'p_Family',\n",
    "        'p_Fantasy', 'p_Film-Noir', 'p_History', 'p_Horror', 'p_Music', 'p_Musical', 'p_Mystery', 'p_News', 'p_Romance',\n",
    "        'p_Sci-Fi', 'p_Short', 'p_Sport', 'p_Thriller', 'p_War', 'p_Western']\n",
    "\n",
    "# Predicción del conjunto de test\n",
    "y_pred_test_genres = clf.predict_proba(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2bdad17b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_Action</th>\n",
       "      <th>p_Adventure</th>\n",
       "      <th>p_Animation</th>\n",
       "      <th>p_Biography</th>\n",
       "      <th>p_Comedy</th>\n",
       "      <th>p_Crime</th>\n",
       "      <th>p_Documentary</th>\n",
       "      <th>p_Drama</th>\n",
       "      <th>p_Family</th>\n",
       "      <th>p_Fantasy</th>\n",
       "      <th>...</th>\n",
       "      <th>p_Musical</th>\n",
       "      <th>p_Mystery</th>\n",
       "      <th>p_News</th>\n",
       "      <th>p_Romance</th>\n",
       "      <th>p_Sci-Fi</th>\n",
       "      <th>p_Short</th>\n",
       "      <th>p_Sport</th>\n",
       "      <th>p_Thriller</th>\n",
       "      <th>p_War</th>\n",
       "      <th>p_Western</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.143030</td>\n",
       "      <td>0.101960</td>\n",
       "      <td>0.024454</td>\n",
       "      <td>0.029938</td>\n",
       "      <td>0.354552</td>\n",
       "      <td>0.138830</td>\n",
       "      <td>0.030787</td>\n",
       "      <td>0.490140</td>\n",
       "      <td>0.073159</td>\n",
       "      <td>0.101339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025069</td>\n",
       "      <td>0.063208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.362818</td>\n",
       "      <td>0.056648</td>\n",
       "      <td>0.008970</td>\n",
       "      <td>0.017522</td>\n",
       "      <td>0.202605</td>\n",
       "      <td>0.033989</td>\n",
       "      <td>0.018117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.122624</td>\n",
       "      <td>0.085786</td>\n",
       "      <td>0.024213</td>\n",
       "      <td>0.084795</td>\n",
       "      <td>0.370949</td>\n",
       "      <td>0.216657</td>\n",
       "      <td>0.080359</td>\n",
       "      <td>0.515684</td>\n",
       "      <td>0.062976</td>\n",
       "      <td>0.067019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024734</td>\n",
       "      <td>0.060935</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.149703</td>\n",
       "      <td>0.058190</td>\n",
       "      <td>0.014248</td>\n",
       "      <td>0.020099</td>\n",
       "      <td>0.204794</td>\n",
       "      <td>0.030438</td>\n",
       "      <td>0.018506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.151364</td>\n",
       "      <td>0.110284</td>\n",
       "      <td>0.013762</td>\n",
       "      <td>0.075334</td>\n",
       "      <td>0.304837</td>\n",
       "      <td>0.448736</td>\n",
       "      <td>0.021010</td>\n",
       "      <td>0.611544</td>\n",
       "      <td>0.081741</td>\n",
       "      <td>0.169121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044538</td>\n",
       "      <td>0.261372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.335987</td>\n",
       "      <td>0.128505</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>0.048658</td>\n",
       "      <td>0.423242</td>\n",
       "      <td>0.052693</td>\n",
       "      <td>0.025351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.154448</td>\n",
       "      <td>0.125772</td>\n",
       "      <td>0.020991</td>\n",
       "      <td>0.064124</td>\n",
       "      <td>0.340779</td>\n",
       "      <td>0.140892</td>\n",
       "      <td>0.009133</td>\n",
       "      <td>0.632038</td>\n",
       "      <td>0.068287</td>\n",
       "      <td>0.063631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131074</td>\n",
       "      <td>0.088418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197224</td>\n",
       "      <td>0.132208</td>\n",
       "      <td>0.001432</td>\n",
       "      <td>0.039743</td>\n",
       "      <td>0.269385</td>\n",
       "      <td>0.077607</td>\n",
       "      <td>0.017862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.175143</td>\n",
       "      <td>0.210069</td>\n",
       "      <td>0.035476</td>\n",
       "      <td>0.032505</td>\n",
       "      <td>0.313850</td>\n",
       "      <td>0.243150</td>\n",
       "      <td>0.021793</td>\n",
       "      <td>0.427885</td>\n",
       "      <td>0.079781</td>\n",
       "      <td>0.143879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023859</td>\n",
       "      <td>0.090359</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.205117</td>\n",
       "      <td>0.241663</td>\n",
       "      <td>0.002634</td>\n",
       "      <td>0.018403</td>\n",
       "      <td>0.259465</td>\n",
       "      <td>0.021569</td>\n",
       "      <td>0.017585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    p_Action  p_Adventure  p_Animation  p_Biography  p_Comedy   p_Crime  \\\n",
       "ID                                                                        \n",
       "1   0.143030     0.101960     0.024454     0.029938  0.354552  0.138830   \n",
       "4   0.122624     0.085786     0.024213     0.084795  0.370949  0.216657   \n",
       "5   0.151364     0.110284     0.013762     0.075334  0.304837  0.448736   \n",
       "6   0.154448     0.125772     0.020991     0.064124  0.340779  0.140892   \n",
       "7   0.175143     0.210069     0.035476     0.032505  0.313850  0.243150   \n",
       "\n",
       "    p_Documentary   p_Drama  p_Family  p_Fantasy  ...  p_Musical  p_Mystery  \\\n",
       "ID                                                ...                         \n",
       "1        0.030787  0.490140  0.073159   0.101339  ...   0.025069   0.063208   \n",
       "4        0.080359  0.515684  0.062976   0.067019  ...   0.024734   0.060935   \n",
       "5        0.021010  0.611544  0.081741   0.169121  ...   0.044538   0.261372   \n",
       "6        0.009133  0.632038  0.068287   0.063631  ...   0.131074   0.088418   \n",
       "7        0.021793  0.427885  0.079781   0.143879  ...   0.023859   0.090359   \n",
       "\n",
       "      p_News  p_Romance  p_Sci-Fi   p_Short   p_Sport  p_Thriller     p_War  \\\n",
       "ID                                                                            \n",
       "1   0.000000   0.362818  0.056648  0.008970  0.017522    0.202605  0.033989   \n",
       "4   0.000477   0.149703  0.058190  0.014248  0.020099    0.204794  0.030438   \n",
       "5   0.000000   0.335987  0.128505  0.001016  0.048658    0.423242  0.052693   \n",
       "6   0.000000   0.197224  0.132208  0.001432  0.039743    0.269385  0.077607   \n",
       "7   0.000048   0.205117  0.241663  0.002634  0.018403    0.259465  0.021569   \n",
       "\n",
       "    p_Western  \n",
       "ID             \n",
       "1    0.018117  \n",
       "4    0.018506  \n",
       "5    0.025351  \n",
       "6    0.017862  \n",
       "7    0.017585  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Guardar predicciones en formato exigido en la competencia de kaggle\n",
    "res = pd.DataFrame(y_pred_test_genres, index=test_data[\"Unnamed: 0\"], columns=cols)\n",
    "res.index.names = ['ID']\n",
    "res.to_csv('pred_genres_text_RF.csv', index_label='ID')\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93809116",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bf53c2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import nltk\n",
    "import re\n",
    "def clean_text(text):\n",
    "    # remove backslash-apostrophe \n",
    "    text = re.sub(\"\\'\", \"\", text) \n",
    "    # remove everything except alphabets \n",
    "    text = re.sub(\"[^a-zA-Z]\",\" \",text) \n",
    "    # remove whitespaces \n",
    "    text = ' '.join(text.split()) \n",
    "    # convert text to lowercase \n",
    "    text = text.lower() \n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4f02e8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['clean_plot'] = train_data['plot'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7f5d91bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\carlo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "476300d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# function to remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    no_stopword_text = [w for w in text.split() if not w in stop_words]\n",
    "    return ' '.join(no_stopword_text)\n",
    "\n",
    "train_data['clean_plot'] = train_data['clean_plot'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4f905915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "#train_data['genres'] = train_data['genres'].map(lambda x: eval(x))\n",
    "le = MultiLabelBinarizer()\n",
    "y_genres = le.fit_transform(train_data['genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c4bfe1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xval, ytrain, yval = train_test_split(train_data['clean_plot'], y_genres, test_size=0.2, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b689ff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=10000)\n",
    "# create TF-IDF features\n",
    "xtrain_tfidf = tfidf_vectorizer.fit_transform(xtrain)\n",
    "xval_tfidf = tfidf_vectorizer.transform(xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "46b788e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=RandomForestClassifier(max_depth=10, n_jobs=-1,\n",
       "                                                     random_state=42))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = OneVsRestClassifier(RandomForestClassifier(n_jobs=-1, n_estimators=100, max_depth=10, random_state=42))\n",
    "clf2.fit(xtrain_tfidf, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "32684ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movie_genres.pkl']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "# Exportar modelo a archivo binario .pkl\n",
    "joblib.dump(clf2, 'movie_genres.pkl', compress=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d4aa13b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tf_idf_vectorizer.pkl']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(tfidf_vectorizer, 'tf_idf_vectorizer.pkl', compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d024e5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf2.predict_proba(xval_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6e5e35bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8034525260869129"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Impresión del desempeño del modelo\n",
    "roc_auc_score(yval, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ce2da379",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_dtm = tfidf_vectorizer.transform(test_data['plot'])\n",
    "\n",
    "cols = ['p_Action', 'p_Adventure', 'p_Animation', 'p_Biography', 'p_Comedy', 'p_Crime', 'p_Documentary', 'p_Drama', 'p_Family',\n",
    "        'p_Fantasy', 'p_Film-Noir', 'p_History', 'p_Horror', 'p_Music', 'p_Musical', 'p_Mystery', 'p_News', 'p_Romance',\n",
    "        'p_Sci-Fi', 'p_Short', 'p_Sport', 'p_Thriller', 'p_War', 'p_Western']\n",
    "\n",
    "# Predicción del conjunto de test\n",
    "y_pred_test_genres = clf2.predict_proba(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ef68d6e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_Action</th>\n",
       "      <th>p_Adventure</th>\n",
       "      <th>p_Animation</th>\n",
       "      <th>p_Biography</th>\n",
       "      <th>p_Comedy</th>\n",
       "      <th>p_Crime</th>\n",
       "      <th>p_Documentary</th>\n",
       "      <th>p_Drama</th>\n",
       "      <th>p_Family</th>\n",
       "      <th>p_Fantasy</th>\n",
       "      <th>...</th>\n",
       "      <th>p_Musical</th>\n",
       "      <th>p_Mystery</th>\n",
       "      <th>p_News</th>\n",
       "      <th>p_Romance</th>\n",
       "      <th>p_Sci-Fi</th>\n",
       "      <th>p_Short</th>\n",
       "      <th>p_Sport</th>\n",
       "      <th>p_Thriller</th>\n",
       "      <th>p_War</th>\n",
       "      <th>p_Western</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.143030</td>\n",
       "      <td>0.101960</td>\n",
       "      <td>0.024454</td>\n",
       "      <td>0.029938</td>\n",
       "      <td>0.354552</td>\n",
       "      <td>0.138830</td>\n",
       "      <td>0.030787</td>\n",
       "      <td>0.490140</td>\n",
       "      <td>0.073159</td>\n",
       "      <td>0.101339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025069</td>\n",
       "      <td>0.063208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.362818</td>\n",
       "      <td>0.056648</td>\n",
       "      <td>0.008970</td>\n",
       "      <td>0.017522</td>\n",
       "      <td>0.202605</td>\n",
       "      <td>0.033989</td>\n",
       "      <td>0.018117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.122624</td>\n",
       "      <td>0.085786</td>\n",
       "      <td>0.024213</td>\n",
       "      <td>0.084795</td>\n",
       "      <td>0.370949</td>\n",
       "      <td>0.216657</td>\n",
       "      <td>0.080359</td>\n",
       "      <td>0.515684</td>\n",
       "      <td>0.062976</td>\n",
       "      <td>0.067019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024734</td>\n",
       "      <td>0.060935</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.149703</td>\n",
       "      <td>0.058190</td>\n",
       "      <td>0.014248</td>\n",
       "      <td>0.020099</td>\n",
       "      <td>0.204794</td>\n",
       "      <td>0.030438</td>\n",
       "      <td>0.018506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.151364</td>\n",
       "      <td>0.110284</td>\n",
       "      <td>0.013762</td>\n",
       "      <td>0.075334</td>\n",
       "      <td>0.304837</td>\n",
       "      <td>0.448736</td>\n",
       "      <td>0.021010</td>\n",
       "      <td>0.611544</td>\n",
       "      <td>0.081741</td>\n",
       "      <td>0.169121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044538</td>\n",
       "      <td>0.261372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.335987</td>\n",
       "      <td>0.128505</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>0.048658</td>\n",
       "      <td>0.423242</td>\n",
       "      <td>0.052693</td>\n",
       "      <td>0.025351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.154448</td>\n",
       "      <td>0.125772</td>\n",
       "      <td>0.020991</td>\n",
       "      <td>0.064124</td>\n",
       "      <td>0.340779</td>\n",
       "      <td>0.140892</td>\n",
       "      <td>0.009133</td>\n",
       "      <td>0.632038</td>\n",
       "      <td>0.068287</td>\n",
       "      <td>0.063631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131074</td>\n",
       "      <td>0.088418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197224</td>\n",
       "      <td>0.132208</td>\n",
       "      <td>0.001432</td>\n",
       "      <td>0.039743</td>\n",
       "      <td>0.269385</td>\n",
       "      <td>0.077607</td>\n",
       "      <td>0.017862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.175143</td>\n",
       "      <td>0.210069</td>\n",
       "      <td>0.035476</td>\n",
       "      <td>0.032505</td>\n",
       "      <td>0.313850</td>\n",
       "      <td>0.243150</td>\n",
       "      <td>0.021793</td>\n",
       "      <td>0.427885</td>\n",
       "      <td>0.079781</td>\n",
       "      <td>0.143879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023859</td>\n",
       "      <td>0.090359</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.205117</td>\n",
       "      <td>0.241663</td>\n",
       "      <td>0.002634</td>\n",
       "      <td>0.018403</td>\n",
       "      <td>0.259465</td>\n",
       "      <td>0.021569</td>\n",
       "      <td>0.017585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    p_Action  p_Adventure  p_Animation  p_Biography  p_Comedy   p_Crime  \\\n",
       "ID                                                                        \n",
       "1   0.143030     0.101960     0.024454     0.029938  0.354552  0.138830   \n",
       "4   0.122624     0.085786     0.024213     0.084795  0.370949  0.216657   \n",
       "5   0.151364     0.110284     0.013762     0.075334  0.304837  0.448736   \n",
       "6   0.154448     0.125772     0.020991     0.064124  0.340779  0.140892   \n",
       "7   0.175143     0.210069     0.035476     0.032505  0.313850  0.243150   \n",
       "\n",
       "    p_Documentary   p_Drama  p_Family  p_Fantasy  ...  p_Musical  p_Mystery  \\\n",
       "ID                                                ...                         \n",
       "1        0.030787  0.490140  0.073159   0.101339  ...   0.025069   0.063208   \n",
       "4        0.080359  0.515684  0.062976   0.067019  ...   0.024734   0.060935   \n",
       "5        0.021010  0.611544  0.081741   0.169121  ...   0.044538   0.261372   \n",
       "6        0.009133  0.632038  0.068287   0.063631  ...   0.131074   0.088418   \n",
       "7        0.021793  0.427885  0.079781   0.143879  ...   0.023859   0.090359   \n",
       "\n",
       "      p_News  p_Romance  p_Sci-Fi   p_Short   p_Sport  p_Thriller     p_War  \\\n",
       "ID                                                                            \n",
       "1   0.000000   0.362818  0.056648  0.008970  0.017522    0.202605  0.033989   \n",
       "4   0.000477   0.149703  0.058190  0.014248  0.020099    0.204794  0.030438   \n",
       "5   0.000000   0.335987  0.128505  0.001016  0.048658    0.423242  0.052693   \n",
       "6   0.000000   0.197224  0.132208  0.001432  0.039743    0.269385  0.077607   \n",
       "7   0.000048   0.205117  0.241663  0.002634  0.018403    0.259465  0.021569   \n",
       "\n",
       "    p_Western  \n",
       "ID             \n",
       "1    0.018117  \n",
       "4    0.018506  \n",
       "5    0.025351  \n",
       "6    0.017862  \n",
       "7    0.017585  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Guardar predicciones en formato exigido en la competencia de kaggle\n",
    "res2 = pd.DataFrame(y_pred_test_genres, index=test_data[\"Unnamed: 0\"], columns=cols)\n",
    "res2.index.names = ['ID']\n",
    "res2.to_csv('pred_genres_text_RF2.csv', index_label='ID')\n",
    "res2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "14cc0a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_Action</th>\n",
       "      <th>p_Adventure</th>\n",
       "      <th>p_Animation</th>\n",
       "      <th>p_Biography</th>\n",
       "      <th>p_Comedy</th>\n",
       "      <th>p_Crime</th>\n",
       "      <th>p_Documentary</th>\n",
       "      <th>p_Drama</th>\n",
       "      <th>p_Family</th>\n",
       "      <th>p_Fantasy</th>\n",
       "      <th>...</th>\n",
       "      <th>p_Musical</th>\n",
       "      <th>p_Mystery</th>\n",
       "      <th>p_News</th>\n",
       "      <th>p_Romance</th>\n",
       "      <th>p_Sci-Fi</th>\n",
       "      <th>p_Short</th>\n",
       "      <th>p_Sport</th>\n",
       "      <th>p_Thriller</th>\n",
       "      <th>p_War</th>\n",
       "      <th>p_Western</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.146403</td>\n",
       "      <td>0.110016</td>\n",
       "      <td>0.027191</td>\n",
       "      <td>0.038849</td>\n",
       "      <td>0.362690</td>\n",
       "      <td>0.144804</td>\n",
       "      <td>0.039736</td>\n",
       "      <td>0.541229</td>\n",
       "      <td>0.074550</td>\n",
       "      <td>0.086762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037149</td>\n",
       "      <td>0.082996</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.269102</td>\n",
       "      <td>0.068860</td>\n",
       "      <td>0.036487</td>\n",
       "      <td>0.022546</td>\n",
       "      <td>0.212701</td>\n",
       "      <td>0.030017</td>\n",
       "      <td>0.020649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.137836</td>\n",
       "      <td>0.109605</td>\n",
       "      <td>0.027442</td>\n",
       "      <td>0.051369</td>\n",
       "      <td>0.345171</td>\n",
       "      <td>0.180244</td>\n",
       "      <td>0.038912</td>\n",
       "      <td>0.512560</td>\n",
       "      <td>0.074550</td>\n",
       "      <td>0.072704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027681</td>\n",
       "      <td>0.074671</td>\n",
       "      <td>0.001055</td>\n",
       "      <td>0.199228</td>\n",
       "      <td>0.068860</td>\n",
       "      <td>0.006651</td>\n",
       "      <td>0.022801</td>\n",
       "      <td>0.231268</td>\n",
       "      <td>0.036620</td>\n",
       "      <td>0.020649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.163105</td>\n",
       "      <td>0.122196</td>\n",
       "      <td>0.027442</td>\n",
       "      <td>0.045504</td>\n",
       "      <td>0.337930</td>\n",
       "      <td>0.344983</td>\n",
       "      <td>0.038912</td>\n",
       "      <td>0.594983</td>\n",
       "      <td>0.080904</td>\n",
       "      <td>0.095083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027681</td>\n",
       "      <td>0.146189</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.260399</td>\n",
       "      <td>0.075398</td>\n",
       "      <td>0.006717</td>\n",
       "      <td>0.022801</td>\n",
       "      <td>0.375036</td>\n",
       "      <td>0.031262</td>\n",
       "      <td>0.020649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.144644</td>\n",
       "      <td>0.125953</td>\n",
       "      <td>0.027719</td>\n",
       "      <td>0.039593</td>\n",
       "      <td>0.325785</td>\n",
       "      <td>0.165350</td>\n",
       "      <td>0.055603</td>\n",
       "      <td>0.543277</td>\n",
       "      <td>0.074370</td>\n",
       "      <td>0.080536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033397</td>\n",
       "      <td>0.093970</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.286645</td>\n",
       "      <td>0.081109</td>\n",
       "      <td>0.006717</td>\n",
       "      <td>0.040001</td>\n",
       "      <td>0.290960</td>\n",
       "      <td>0.057798</td>\n",
       "      <td>0.020649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.166127</td>\n",
       "      <td>0.145378</td>\n",
       "      <td>0.056343</td>\n",
       "      <td>0.054650</td>\n",
       "      <td>0.355207</td>\n",
       "      <td>0.174083</td>\n",
       "      <td>0.048402</td>\n",
       "      <td>0.439607</td>\n",
       "      <td>0.076703</td>\n",
       "      <td>0.114447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027681</td>\n",
       "      <td>0.153273</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.195608</td>\n",
       "      <td>0.218631</td>\n",
       "      <td>0.006717</td>\n",
       "      <td>0.022801</td>\n",
       "      <td>0.255787</td>\n",
       "      <td>0.030017</td>\n",
       "      <td>0.020649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11263</th>\n",
       "      <td>0.189546</td>\n",
       "      <td>0.110771</td>\n",
       "      <td>0.027442</td>\n",
       "      <td>0.038804</td>\n",
       "      <td>0.374987</td>\n",
       "      <td>0.174690</td>\n",
       "      <td>0.038871</td>\n",
       "      <td>0.497717</td>\n",
       "      <td>0.077479</td>\n",
       "      <td>0.072704</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027681</td>\n",
       "      <td>0.074671</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.219019</td>\n",
       "      <td>0.068860</td>\n",
       "      <td>0.006717</td>\n",
       "      <td>0.022801</td>\n",
       "      <td>0.247335</td>\n",
       "      <td>0.030017</td>\n",
       "      <td>0.020202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11265</th>\n",
       "      <td>0.149865</td>\n",
       "      <td>0.132504</td>\n",
       "      <td>0.035145</td>\n",
       "      <td>0.038804</td>\n",
       "      <td>0.388764</td>\n",
       "      <td>0.142649</td>\n",
       "      <td>0.059201</td>\n",
       "      <td>0.479780</td>\n",
       "      <td>0.074550</td>\n",
       "      <td>0.076315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082165</td>\n",
       "      <td>0.075632</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.260663</td>\n",
       "      <td>0.133122</td>\n",
       "      <td>0.006717</td>\n",
       "      <td>0.028591</td>\n",
       "      <td>0.224796</td>\n",
       "      <td>0.029662</td>\n",
       "      <td>0.020649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11269</th>\n",
       "      <td>0.138971</td>\n",
       "      <td>0.111534</td>\n",
       "      <td>0.027554</td>\n",
       "      <td>0.038804</td>\n",
       "      <td>0.410753</td>\n",
       "      <td>0.170518</td>\n",
       "      <td>0.039776</td>\n",
       "      <td>0.540827</td>\n",
       "      <td>0.085877</td>\n",
       "      <td>0.077165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054375</td>\n",
       "      <td>0.077170</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.269569</td>\n",
       "      <td>0.068860</td>\n",
       "      <td>0.006717</td>\n",
       "      <td>0.022912</td>\n",
       "      <td>0.216471</td>\n",
       "      <td>0.030285</td>\n",
       "      <td>0.020649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11270</th>\n",
       "      <td>0.167459</td>\n",
       "      <td>0.338030</td>\n",
       "      <td>0.029189</td>\n",
       "      <td>0.045504</td>\n",
       "      <td>0.432730</td>\n",
       "      <td>0.144967</td>\n",
       "      <td>0.038912</td>\n",
       "      <td>0.469566</td>\n",
       "      <td>0.108124</td>\n",
       "      <td>0.074735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070302</td>\n",
       "      <td>0.075609</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.241669</td>\n",
       "      <td>0.070153</td>\n",
       "      <td>0.006717</td>\n",
       "      <td>0.022801</td>\n",
       "      <td>0.225621</td>\n",
       "      <td>0.031308</td>\n",
       "      <td>0.023453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11275</th>\n",
       "      <td>0.171732</td>\n",
       "      <td>0.121787</td>\n",
       "      <td>0.027442</td>\n",
       "      <td>0.038804</td>\n",
       "      <td>0.367478</td>\n",
       "      <td>0.223637</td>\n",
       "      <td>0.040689</td>\n",
       "      <td>0.442500</td>\n",
       "      <td>0.119325</td>\n",
       "      <td>0.080588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027681</td>\n",
       "      <td>0.117968</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.185489</td>\n",
       "      <td>0.187823</td>\n",
       "      <td>0.006717</td>\n",
       "      <td>0.022801</td>\n",
       "      <td>0.309519</td>\n",
       "      <td>0.030017</td>\n",
       "      <td>0.020649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3383 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       p_Action  p_Adventure  p_Animation  p_Biography  p_Comedy   p_Crime  \\\n",
       "ID                                                                           \n",
       "1      0.146403     0.110016     0.027191     0.038849  0.362690  0.144804   \n",
       "4      0.137836     0.109605     0.027442     0.051369  0.345171  0.180244   \n",
       "5      0.163105     0.122196     0.027442     0.045504  0.337930  0.344983   \n",
       "6      0.144644     0.125953     0.027719     0.039593  0.325785  0.165350   \n",
       "7      0.166127     0.145378     0.056343     0.054650  0.355207  0.174083   \n",
       "...         ...          ...          ...          ...       ...       ...   \n",
       "11263  0.189546     0.110771     0.027442     0.038804  0.374987  0.174690   \n",
       "11265  0.149865     0.132504     0.035145     0.038804  0.388764  0.142649   \n",
       "11269  0.138971     0.111534     0.027554     0.038804  0.410753  0.170518   \n",
       "11270  0.167459     0.338030     0.029189     0.045504  0.432730  0.144967   \n",
       "11275  0.171732     0.121787     0.027442     0.038804  0.367478  0.223637   \n",
       "\n",
       "       p_Documentary   p_Drama  p_Family  p_Fantasy  ...  p_Musical  \\\n",
       "ID                                                   ...              \n",
       "1           0.039736  0.541229  0.074550   0.086762  ...   0.037149   \n",
       "4           0.038912  0.512560  0.074550   0.072704  ...   0.027681   \n",
       "5           0.038912  0.594983  0.080904   0.095083  ...   0.027681   \n",
       "6           0.055603  0.543277  0.074370   0.080536  ...   0.033397   \n",
       "7           0.048402  0.439607  0.076703   0.114447  ...   0.027681   \n",
       "...              ...       ...       ...        ...  ...        ...   \n",
       "11263       0.038871  0.497717  0.077479   0.072704  ...   0.027681   \n",
       "11265       0.059201  0.479780  0.074550   0.076315  ...   0.082165   \n",
       "11269       0.039776  0.540827  0.085877   0.077165  ...   0.054375   \n",
       "11270       0.038912  0.469566  0.108124   0.074735  ...   0.070302   \n",
       "11275       0.040689  0.442500  0.119325   0.080588  ...   0.027681   \n",
       "\n",
       "       p_Mystery    p_News  p_Romance  p_Sci-Fi   p_Short   p_Sport  \\\n",
       "ID                                                                    \n",
       "1       0.082996  0.000042   0.269102  0.068860  0.036487  0.022546   \n",
       "4       0.074671  0.001055   0.199228  0.068860  0.006651  0.022801   \n",
       "5       0.146189  0.000024   0.260399  0.075398  0.006717  0.022801   \n",
       "6       0.093970  0.000028   0.286645  0.081109  0.006717  0.040001   \n",
       "7       0.153273  0.000081   0.195608  0.218631  0.006717  0.022801   \n",
       "...          ...       ...        ...       ...       ...       ...   \n",
       "11263   0.074671  0.000102   0.219019  0.068860  0.006717  0.022801   \n",
       "11265   0.075632  0.000086   0.260663  0.133122  0.006717  0.028591   \n",
       "11269   0.077170  0.000033   0.269569  0.068860  0.006717  0.022912   \n",
       "11270   0.075609  0.000074   0.241669  0.070153  0.006717  0.022801   \n",
       "11275   0.117968  0.000088   0.185489  0.187823  0.006717  0.022801   \n",
       "\n",
       "       p_Thriller     p_War  p_Western  \n",
       "ID                                      \n",
       "1        0.212701  0.030017   0.020649  \n",
       "4        0.231268  0.036620   0.020649  \n",
       "5        0.375036  0.031262   0.020649  \n",
       "6        0.290960  0.057798   0.020649  \n",
       "7        0.255787  0.030017   0.020649  \n",
       "...           ...       ...        ...  \n",
       "11263    0.247335  0.030017   0.020202  \n",
       "11265    0.224796  0.029662   0.020649  \n",
       "11269    0.216471  0.030285   0.020649  \n",
       "11270    0.225621  0.031308   0.023453  \n",
       "11275    0.309519  0.030017   0.020649  \n",
       "\n",
       "[3383 rows x 24 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4bcb09",
   "metadata": {},
   "source": [
    "## part 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6575464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "clf3 = OneVsRestClassifier(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f1e957fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression())"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3.fit(xtrain_tfidf, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b7fad7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = clf3.predict_proba(xval_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "dac40ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movie_genres_real.pkl']"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "# Exportar modelo a archivo binario .pkl\n",
    "joblib.dump(clf3, 'movie_genres_real.pkl', compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "558cb2b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8812263836617923"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Impresión del desempeño del modelo\n",
    "roc_auc_score(yval, y_pred3, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "76a97e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_dtm = tfidf_vectorizer.transform(test_data['plot'])\n",
    "\n",
    "cols = ['p_Action', 'p_Adventure', 'p_Animation', 'p_Biography', 'p_Comedy', 'p_Crime', 'p_Documentary', 'p_Drama', 'p_Family',\n",
    "        'p_Fantasy', 'p_Film-Noir', 'p_History', 'p_Horror', 'p_Music', 'p_Musical', 'p_Mystery', 'p_News', 'p_Romance',\n",
    "        'p_Sci-Fi', 'p_Short', 'p_Sport', 'p_Thriller', 'p_War', 'p_Western']\n",
    "\n",
    "# Predicción del conjunto de test\n",
    "y_pred_test_genres3 = clf3.predict_proba(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4ee52dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_Action</th>\n",
       "      <th>p_Adventure</th>\n",
       "      <th>p_Animation</th>\n",
       "      <th>p_Biography</th>\n",
       "      <th>p_Comedy</th>\n",
       "      <th>p_Crime</th>\n",
       "      <th>p_Documentary</th>\n",
       "      <th>p_Drama</th>\n",
       "      <th>p_Family</th>\n",
       "      <th>p_Fantasy</th>\n",
       "      <th>...</th>\n",
       "      <th>p_Musical</th>\n",
       "      <th>p_Mystery</th>\n",
       "      <th>p_News</th>\n",
       "      <th>p_Romance</th>\n",
       "      <th>p_Sci-Fi</th>\n",
       "      <th>p_Short</th>\n",
       "      <th>p_Sport</th>\n",
       "      <th>p_Thriller</th>\n",
       "      <th>p_War</th>\n",
       "      <th>p_Western</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.133067</td>\n",
       "      <td>0.124584</td>\n",
       "      <td>0.033603</td>\n",
       "      <td>0.035040</td>\n",
       "      <td>0.336381</td>\n",
       "      <td>0.127381</td>\n",
       "      <td>0.026928</td>\n",
       "      <td>0.566943</td>\n",
       "      <td>0.079180</td>\n",
       "      <td>0.119472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033962</td>\n",
       "      <td>0.106657</td>\n",
       "      <td>0.000918</td>\n",
       "      <td>0.528938</td>\n",
       "      <td>0.058112</td>\n",
       "      <td>0.010412</td>\n",
       "      <td>0.025240</td>\n",
       "      <td>0.179519</td>\n",
       "      <td>0.027056</td>\n",
       "      <td>0.030495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.130723</td>\n",
       "      <td>0.050986</td>\n",
       "      <td>0.029530</td>\n",
       "      <td>0.120008</td>\n",
       "      <td>0.316369</td>\n",
       "      <td>0.228220</td>\n",
       "      <td>0.058147</td>\n",
       "      <td>0.735390</td>\n",
       "      <td>0.046065</td>\n",
       "      <td>0.036749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034187</td>\n",
       "      <td>0.039291</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>0.112300</td>\n",
       "      <td>0.028186</td>\n",
       "      <td>0.010781</td>\n",
       "      <td>0.034896</td>\n",
       "      <td>0.223570</td>\n",
       "      <td>0.045118</td>\n",
       "      <td>0.024818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.129682</td>\n",
       "      <td>0.041176</td>\n",
       "      <td>0.015846</td>\n",
       "      <td>0.047590</td>\n",
       "      <td>0.204104</td>\n",
       "      <td>0.656877</td>\n",
       "      <td>0.036500</td>\n",
       "      <td>0.700048</td>\n",
       "      <td>0.028143</td>\n",
       "      <td>0.043257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020628</td>\n",
       "      <td>0.318470</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>0.129302</td>\n",
       "      <td>0.067476</td>\n",
       "      <td>0.009167</td>\n",
       "      <td>0.022839</td>\n",
       "      <td>0.488773</td>\n",
       "      <td>0.027166</td>\n",
       "      <td>0.021656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.106001</td>\n",
       "      <td>0.089515</td>\n",
       "      <td>0.021637</td>\n",
       "      <td>0.055035</td>\n",
       "      <td>0.203494</td>\n",
       "      <td>0.077088</td>\n",
       "      <td>0.033174</td>\n",
       "      <td>0.656007</td>\n",
       "      <td>0.057235</td>\n",
       "      <td>0.053097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038491</td>\n",
       "      <td>0.106711</td>\n",
       "      <td>0.000937</td>\n",
       "      <td>0.193923</td>\n",
       "      <td>0.087923</td>\n",
       "      <td>0.007794</td>\n",
       "      <td>0.029242</td>\n",
       "      <td>0.280182</td>\n",
       "      <td>0.076899</td>\n",
       "      <td>0.021391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.074203</td>\n",
       "      <td>0.076171</td>\n",
       "      <td>0.030783</td>\n",
       "      <td>0.028179</td>\n",
       "      <td>0.233582</td>\n",
       "      <td>0.115021</td>\n",
       "      <td>0.030421</td>\n",
       "      <td>0.346483</td>\n",
       "      <td>0.053185</td>\n",
       "      <td>0.111507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024257</td>\n",
       "      <td>0.132572</td>\n",
       "      <td>0.000938</td>\n",
       "      <td>0.162058</td>\n",
       "      <td>0.326006</td>\n",
       "      <td>0.009542</td>\n",
       "      <td>0.017376</td>\n",
       "      <td>0.445691</td>\n",
       "      <td>0.020379</td>\n",
       "      <td>0.022391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    p_Action  p_Adventure  p_Animation  p_Biography  p_Comedy   p_Crime  \\\n",
       "ID                                                                        \n",
       "1   0.133067     0.124584     0.033603     0.035040  0.336381  0.127381   \n",
       "4   0.130723     0.050986     0.029530     0.120008  0.316369  0.228220   \n",
       "5   0.129682     0.041176     0.015846     0.047590  0.204104  0.656877   \n",
       "6   0.106001     0.089515     0.021637     0.055035  0.203494  0.077088   \n",
       "7   0.074203     0.076171     0.030783     0.028179  0.233582  0.115021   \n",
       "\n",
       "    p_Documentary   p_Drama  p_Family  p_Fantasy  ...  p_Musical  p_Mystery  \\\n",
       "ID                                                ...                         \n",
       "1        0.026928  0.566943  0.079180   0.119472  ...   0.033962   0.106657   \n",
       "4        0.058147  0.735390  0.046065   0.036749  ...   0.034187   0.039291   \n",
       "5        0.036500  0.700048  0.028143   0.043257  ...   0.020628   0.318470   \n",
       "6        0.033174  0.656007  0.057235   0.053097  ...   0.038491   0.106711   \n",
       "7        0.030421  0.346483  0.053185   0.111507  ...   0.024257   0.132572   \n",
       "\n",
       "      p_News  p_Romance  p_Sci-Fi   p_Short   p_Sport  p_Thriller     p_War  \\\n",
       "ID                                                                            \n",
       "1   0.000918   0.528938  0.058112  0.010412  0.025240    0.179519  0.027056   \n",
       "4   0.001026   0.112300  0.028186  0.010781  0.034896    0.223570  0.045118   \n",
       "5   0.001116   0.129302  0.067476  0.009167  0.022839    0.488773  0.027166   \n",
       "6   0.000937   0.193923  0.087923  0.007794  0.029242    0.280182  0.076899   \n",
       "7   0.000938   0.162058  0.326006  0.009542  0.017376    0.445691  0.020379   \n",
       "\n",
       "    p_Western  \n",
       "ID             \n",
       "1    0.030495  \n",
       "4    0.024818  \n",
       "5    0.021656  \n",
       "6    0.021391  \n",
       "7    0.022391  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Guardar predicciones en formato exigido en la competencia de kaggle\n",
    "res3 = pd.DataFrame(y_pred_test_genres3, index=test_data[\"Unnamed: 0\"], columns=cols)\n",
    "res3.index.names = ['ID']\n",
    "res3.to_csv('pred_genres_text_RF3.csv', index_label='ID')\n",
    "res3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2721ee",
   "metadata": {},
   "source": [
    "## Part 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9fd434c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = np.linspace(100, 3000, int((3000-100)/200) + 1, dtype=int)\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [1, 5, 10, 20, 50, 75, 100, 150, 200]\n",
    "# Minimum number of samples required to split a node\n",
    "# min_samples_split = [int(x) for x in np.linspace(start = 2, stop = 10, num = 9)]\n",
    "min_samples_split = [1, 2, 5, 10, 15, 20, 30]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 3, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Criterion\n",
    "criterion=['gini', 'entropy']\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "#                'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap,\n",
    "               'criterion': criterion}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "86bc6afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "rf_base = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(estimator = rf_base,\n",
    "                               param_distributions = random_grid,\n",
    "                               n_iter = 30, cv = 5,\n",
    "                               verbose=2,\n",
    "                               random_state=42, n_jobs = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "aa0e314c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "15 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.83475131 0.83361692 0.83361692 0.83494035 0.83399499 0.83361692\n",
      " 0.83494053 0.83418402 0.83399499 0.83361692 0.83683089 0.83361692\n",
      "        nan 0.83758739 0.83361692 0.83361692 0.8362636  0.83361692\n",
      "        nan 0.83361692 0.83758703 0.83494053 0.83418402 0.83361674\n",
      " 0.83380595        nan 0.83550746 0.83361692 0.83361692 0.83645246]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "15 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.87143143 0.87067511 0.87067511 0.87105336 0.87067511 0.87067511\n",
      " 0.87086433 0.87067511 0.87067511 0.87067511 0.87162047 0.87067511\n",
      "        nan 0.87256583 0.87067511 0.87067511 0.87162047 0.87067511\n",
      "        nan 0.87067511 0.87218793 0.87105336 0.87067511 0.87067511\n",
      " 0.87067511        nan 0.87199854 0.87067511 0.87067511 0.87199872]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "15 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.96955949 0.96955949 0.96955949 0.96955949 0.96955949 0.96955949\n",
      " 0.96955949 0.96955949 0.96955949 0.96955949 0.96955949 0.96955949\n",
      "        nan 0.96993775 0.96955949 0.96955949 0.96955949 0.96955949\n",
      "        nan 0.96955949 0.96955949 0.96955949 0.96955949 0.96955949\n",
      " 0.96955949        nan 0.96955949 0.96955949 0.96955949 0.96993775]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "15 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.95405569 0.95405569 0.95405569 0.95405569 0.95405569 0.95405569\n",
      " 0.95405569 0.95405569 0.95405569 0.95405569 0.95405569 0.95405569\n",
      "        nan 0.95405569 0.95405569 0.95405569 0.95405569 0.95405569\n",
      "        nan 0.95405569 0.95405569 0.95405569 0.95405569 0.95405569\n",
      " 0.95405569        nan 0.95405569 0.95405569 0.95405569 0.95386665]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "15 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.68576043 0.63906265 0.65967168 0.6867065  0.66307308 0.62015495\n",
      " 0.68443789 0.68330385 0.68235778 0.62128952 0.69805044 0.6193988\n",
      "        nan 0.69521473 0.61845345 0.61845345 0.69181065 0.62015495\n",
      "        nan 0.61977688 0.69483648 0.68859793 0.68670704 0.67933213\n",
      " 0.66137122        nan 0.6844361  0.63792826 0.61920977 0.68954132]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "15 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.84193611 0.82019286 0.82945705 0.84307014 0.83304981 0.81489896\n",
      " 0.83853275 0.83853185 0.83588571 0.81489896 0.84741797 0.81489896\n",
      "        nan 0.84666165 0.81489896 0.81489896 0.84439357 0.81489896\n",
      "        nan 0.81489896 0.84571647 0.84288111 0.83928853 0.83569739\n",
      " 0.83267174        nan 0.84325829 0.818491   0.81489896 0.84609508]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "15 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.95235365 0.94516921 0.94895064 0.95140829 0.95008486 0.94516921\n",
      " 0.94989582 0.95084083 0.95027372 0.94516921 0.95329919 0.94516921\n",
      "        nan 0.95405515 0.94516921 0.94516921 0.95159715 0.94516921\n",
      "        nan 0.94516921 0.95367708 0.95121908 0.95103004 0.94876143\n",
      " 0.94932872        nan 0.95254269 0.94516921 0.94516921 0.95311015]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "15 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.67574152 0.65796589 0.66571994 0.67006973 0.66496361 0.64057548\n",
      " 0.6679889  0.6708257  0.67101563 0.64227644 0.67328298 0.63962976\n",
      "        nan 0.67573866 0.61051108 0.60900004 0.67271588 0.64000783\n",
      "        nan 0.64303259 0.67176927 0.67120269 0.67176927 0.66364072\n",
      " 0.66628794        nan 0.66439758 0.657779   0.64170808 0.67101151]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "15 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.91869918 0.91869918 0.91869918 0.91869918 0.91869918 0.91869918\n",
      " 0.91869918 0.91869918 0.91869918 0.91869918 0.91907743 0.91869918\n",
      "        nan 0.91907743 0.91869918 0.91869918 0.91869918 0.91869918\n",
      "        nan 0.91869918 0.91926646 0.91869918 0.91869918 0.91869918\n",
      " 0.91869918        nan 0.91869918 0.91869918 0.91869918 0.91888821]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "15 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.91264913 0.91227088 0.91227088 0.91227088 0.91227088 0.91227088\n",
      " 0.91227088 0.91227088 0.91227088 0.91227088 0.91283817 0.91227088\n",
      "        nan 0.91283817 0.91227088 0.91227088 0.91245992 0.91227088\n",
      "        nan 0.91227088 0.91264895 0.91227088 0.91227088 0.91227088\n",
      " 0.91227088        nan 0.91227088 0.91227088 0.91227088 0.91302702]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "15 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.97901308 0.97901308 0.97901308 0.97901308 0.97901308 0.97901308\n",
      " 0.97901308 0.97901308 0.97901308 0.97901308 0.97901308 0.97901308\n",
      "        nan 0.97901308 0.97901308 0.97901308 0.97901308 0.97901308\n",
      "        nan 0.97901308 0.97901308 0.97901308 0.97901308 0.97901308\n",
      " 0.97901308        nan 0.97901308 0.97901308 0.97901308 0.97901308]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "15 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.96350927 0.96350927 0.96350927 0.96350927 0.96350927 0.96350927\n",
      " 0.96350927 0.96350927 0.96350927 0.96350927 0.96350927 0.96350927\n",
      "        nan 0.96350927 0.96350927 0.96350927 0.96350927 0.96350927\n",
      "        nan 0.96350927 0.96350927 0.96350927 0.96350927 0.96350927\n",
      " 0.96350927        nan 0.96350927 0.96350927 0.96350927 0.96350927]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "15 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.8765363  0.87634726 0.8765363  0.8765363  0.8765363  0.87634726\n",
      " 0.8765363  0.8765363  0.8765363  0.87634726 0.8765363  0.87634726\n",
      "        nan 0.87767069 0.87634726 0.87634726 0.8765363  0.87634726\n",
      "        nan 0.87634726 0.87672533 0.87672551 0.8765363  0.87634726\n",
      " 0.8765363         nan 0.87672551 0.87634726 0.87634726 0.8765363 ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "15 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.95953862 0.95878248 0.95878248 0.95897152 0.95916055 0.95878248\n",
      " 0.95878248 0.95897152 0.95878248 0.95878248 0.96124066 0.95878248\n",
      "        nan 0.96086241 0.95878248 0.95878248 0.96010609 0.95878248\n",
      "        nan 0.95878248 0.96124084 0.95934959 0.95897152 0.95878248\n",
      " 0.95878248        nan 0.96029512 0.95878248 0.95878248 0.96067338]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "15 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.96710167 0.96710167 0.96710167 0.96710167 0.96710167 0.96710167\n",
      " 0.96710167 0.96710167 0.96710167 0.96710167 0.96710167 0.96710167\n",
      "        nan 0.96710167 0.96710167 0.96710167 0.96710167 0.96710167\n",
      "        nan 0.96710167 0.96710167 0.96710167 0.96710167 0.96710167\n",
      " 0.96710167        nan 0.96710167 0.96710167 0.96710167 0.96710167]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "15 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.90225001 0.90225001 0.90225001 0.90225001 0.90225001 0.90225001\n",
      " 0.90225001 0.90225001 0.90225001 0.90225001 0.90225001 0.90225001\n",
      "        nan 0.90225001 0.90225001 0.90225001 0.90225001 0.90225001\n",
      "        nan 0.90225001 0.9020608  0.90225001 0.90225001 0.90225001\n",
      " 0.90225001        nan 0.90225001 0.90225001 0.90225001 0.9020608 ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1046\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1047\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    778\u001b[0m job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callback:\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[1;32m--> 216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\sklearn\\multiclass.py:85\u001b[0m, in \u001b[0;36m_fit_binary\u001b[1;34m(estimator, X, y, classes)\u001b[0m\n\u001b[0;32m     84\u001b[0m     estimator \u001b[38;5;241m=\u001b[39m clone(estimator)\n\u001b[1;32m---> 85\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 891\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1766\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1766\u001b[0m \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1767\u001b[0m \u001b[43m    \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1768\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m   1769\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1770\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    831\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    832\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    833\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    834\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    835\u001b[0m         )\n\u001b[0;32m    836\u001b[0m     )\n\u001b[1;32m--> 838\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\joblib\\parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\joblib\\parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 935\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    936\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\concurrent\\futures\\_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 441\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 312\u001b[0m     \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    313\u001b[0m     gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [141]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m##First classifier\u001b[39;00m\n\u001b[0;32m      2\u001b[0m clf \u001b[38;5;241m=\u001b[39m OneVsRestClassifier(rf_random)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_genres\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\sklearn\\multiclass.py:337\u001b[0m, in \u001b[0;36mOneVsRestClassifier.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    333\u001b[0m columns \u001b[38;5;241m=\u001b[39m (col\u001b[38;5;241m.\u001b[39mtoarray()\u001b[38;5;241m.\u001b[39mravel() \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m Y\u001b[38;5;241m.\u001b[39mT)\n\u001b[0;32m    334\u001b[0m \u001b[38;5;66;03m# In cases where individual estimators are very fast to train setting\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;66;03m# n_jobs > 1 in can results in slower performance due to the overhead\u001b[39;00m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;66;03m# of spawning threads.  See joblib issue #112.\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_binary\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnot \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_binarizer_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_binarizer_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    351\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_features_in_\n",
      "File \u001b[1;32mD:\\anaconda\\lib\\site-packages\\joblib\\parallel.py:1068\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1066\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_terminate_backend()\n\u001b[0;32m   1067\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[1;32m-> 1068\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241m.\u001b[39m_pickle_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1069\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\n\u001b[0;32m   1070\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##First classifier\n",
    "clf4 = OneVsRestClassifier(rf_random)\n",
    "clf4.fit(X_train, y_train_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd49f17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred4 = clf4.predict_proba(xval_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be124a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impresión del desempeño del modelo\n",
    "roc_auc_score(yval, y_pred4, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ad2ed7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
